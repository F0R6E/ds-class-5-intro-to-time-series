{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries Operations\n",
    "\n",
    "In this lesson we'll explore time shifting and resampling (grouping). Two of the most common operations with Time Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    494.003230\n",
       "2018-01-02    480.841094\n",
       "2018-01-03    507.142622\n",
       "2018-01-04    502.390595\n",
       "2018-01-05    492.511207\n",
       "2018-01-06    488.935809\n",
       "2018-01-07    495.473784\n",
       "2018-01-08    503.057518\n",
       "2018-01-09    496.182339\n",
       "2018-01-10    504.085163\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01           NaN\n",
       "2018-01-02    494.003230\n",
       "2018-01-03    480.841094\n",
       "2018-01-04    507.142622\n",
       "2018-01-05    502.390595\n",
       "2018-01-06    492.511207\n",
       "2018-01-07    488.935809\n",
       "2018-01-08    495.473784\n",
       "2018-01-09    503.057518\n",
       "2018-01-10    496.182339\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shfit (1)</th>\n",
       "      <th>Shift (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>494.003230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>480.841094</td>\n",
       "      <td>494.003230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>507.142622</td>\n",
       "      <td>480.841094</td>\n",
       "      <td>494.003230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>502.390595</td>\n",
       "      <td>507.142622</td>\n",
       "      <td>480.841094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>492.511207</td>\n",
       "      <td>502.390595</td>\n",
       "      <td>507.142622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>488.935809</td>\n",
       "      <td>492.511207</td>\n",
       "      <td>502.390595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>495.473784</td>\n",
       "      <td>488.935809</td>\n",
       "      <td>492.511207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>503.057518</td>\n",
       "      <td>495.473784</td>\n",
       "      <td>488.935809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>496.182339</td>\n",
       "      <td>503.057518</td>\n",
       "      <td>495.473784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>504.085163</td>\n",
       "      <td>496.182339</td>\n",
       "      <td>503.057518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original   Shfit (1)   Shift (2)\n",
       "2018-01-01  494.003230         NaN         NaN\n",
       "2018-01-02  480.841094  494.003230         NaN\n",
       "2018-01-03  507.142622  480.841094  494.003230\n",
       "2018-01-04  502.390595  507.142622  480.841094\n",
       "2018-01-05  492.511207  502.390595  507.142622\n",
       "2018-01-06  488.935809  492.511207  502.390595\n",
       "2018-01-07  495.473784  488.935809  492.511207\n",
       "2018-01-08  503.057518  495.473784  488.935809\n",
       "2018-01-09  496.182339  503.057518  495.473784\n",
       "2018-01-10  504.085163  496.182339  503.057518"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shfit (1)': ts.shift(1),\n",
    "    'Shift (2)': ts.shift(2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations are usually employed to compare the timeseries with previous values of the same time series. For example, calculating the percent change over the previous period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>494.003230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>480.841094</td>\n",
       "      <td>494.003230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>507.142622</td>\n",
       "      <td>480.841094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>502.390595</td>\n",
       "      <td>507.142622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>492.511207</td>\n",
       "      <td>502.390595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>488.935809</td>\n",
       "      <td>492.511207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>495.473784</td>\n",
       "      <td>488.935809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>503.057518</td>\n",
       "      <td>495.473784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>496.182339</td>\n",
       "      <td>503.057518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>504.085163</td>\n",
       "      <td>496.182339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original     Shifted\n",
       "2018-01-01  494.003230         NaN\n",
       "2018-01-02  480.841094  494.003230\n",
       "2018-01-03  507.142622  480.841094\n",
       "2018-01-04  502.390595  507.142622\n",
       "2018-01-05  492.511207  502.390595\n",
       "2018-01-06  488.935809  492.511207\n",
       "2018-01-07  495.473784  488.935809\n",
       "2018-01-08  503.057518  495.473784\n",
       "2018-01-09  496.182339  503.057518\n",
       "2018-01-10  504.085163  496.182339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shifted': ts.shift(1)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.026644\n",
       "2018-01-03    0.054699\n",
       "2018-01-04   -0.009370\n",
       "2018-01-05   -0.019665\n",
       "2018-01-06   -0.007260\n",
       "2018-01-07    0.013372\n",
       "2018-01-08    0.015306\n",
       "2018-01-09   -0.013667\n",
       "2018-01-10    0.015927\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Original'] / df['Shifted']) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how much sales grew or shrank vs the previous month.\n",
    "\n",
    "This is a particularly silly example, because there's a pandas method specially intended for percentage changes: [`pct_change()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pct_change.html), so we don't even need `shift`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.026644\n",
       "2018-01-03    0.054699\n",
       "2018-01-04   -0.009370\n",
       "2018-01-05   -0.019665\n",
       "2018-01-06   -0.007260\n",
       "2018-01-07    0.013372\n",
       "2018-01-08    0.015306\n",
       "2018-01-09   -0.013667\n",
       "2018-01-10    0.015927\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting also works with smaller periods, just changing the time of the original timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:15:00    494.003230\n",
       "2018-01-02 00:15:00    480.841094\n",
       "2018-01-03 00:15:00    507.142622\n",
       "2018-01-04 00:15:00    502.390595\n",
       "2018-01-05 00:15:00    492.511207\n",
       "2018-01-06 00:15:00    488.935809\n",
       "2018-01-07 00:15:00    495.473784\n",
       "2018-01-08 00:15:00    503.057518\n",
       "2018-01-09 00:15:00    496.182339\n",
       "2018-01-10 00:15:00    504.085163\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1, freq='15Min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Frequency\n",
    "\n",
    "We'll now see how to change the frequency of our indexes. These will be just raw adjustments we'll do to directly modify the frequency of our data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    489.919450\n",
       "2018-01-01 01:00:00    498.998069\n",
       "2018-01-01 02:00:00    499.096276\n",
       "2018-01-01 03:00:00    503.100149\n",
       "2018-01-01 04:00:00    497.605738\n",
       "2018-01-01 05:00:00    504.973549\n",
       "2018-01-01 06:00:00    516.273670\n",
       "2018-01-01 07:00:00    512.838193\n",
       "2018-01-01 08:00:00    504.017753\n",
       "2018-01-01 09:00:00    508.333218\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='H'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    489.919450\n",
       "2018-01-01 00:45:00           NaN\n",
       "2018-01-01 01:30:00           NaN\n",
       "2018-01-01 02:15:00           NaN\n",
       "2018-01-01 03:00:00    503.100149\n",
       "2018-01-01 03:45:00           NaN\n",
       "2018-01-01 04:30:00           NaN\n",
       "2018-01-01 05:15:00           NaN\n",
       "2018-01-01 06:00:00    516.273670\n",
       "2018-01-01 06:45:00           NaN\n",
       "2018-01-01 07:30:00           NaN\n",
       "2018-01-01 08:15:00           NaN\n",
       "2018-01-01 09:00:00    508.333218\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    489.919450\n",
       "2018-01-01 00:45:00    489.919450\n",
       "2018-01-01 01:30:00    498.998069\n",
       "2018-01-01 02:15:00    499.096276\n",
       "2018-01-01 03:00:00    503.100149\n",
       "2018-01-01 03:45:00    503.100149\n",
       "2018-01-01 04:30:00    497.605738\n",
       "2018-01-01 05:15:00    504.973549\n",
       "2018-01-01 06:00:00    516.273670\n",
       "2018-01-01 06:45:00    516.273670\n",
       "2018-01-01 07:30:00    512.838193\n",
       "2018-01-01 08:15:00    504.017753\n",
       "2018-01-01 09:00:00    508.333218\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    489.919450\n",
       "2018-01-01 00:45:00    498.998069\n",
       "2018-01-01 01:30:00    499.096276\n",
       "2018-01-01 02:15:00    503.100149\n",
       "2018-01-01 03:00:00    503.100149\n",
       "2018-01-01 03:45:00    497.605738\n",
       "2018-01-01 04:30:00    504.973549\n",
       "2018-01-01 05:15:00    516.273670\n",
       "2018-01-01 06:00:00    516.273670\n",
       "2018-01-01 06:45:00    512.838193\n",
       "2018-01-01 07:30:00    504.017753\n",
       "2018-01-01 08:15:00    508.333218\n",
       "2018-01-01 09:00:00    508.333218\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.asfreq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these examples, we've gone from a \"less frequent\" index to a \"more frequent\" index. But we could go the other way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    516.845407\n",
       "2018-01-01 00:30:00    502.287105\n",
       "2018-01-01 01:00:00    516.660736\n",
       "2018-01-01 01:30:00    500.727604\n",
       "2018-01-01 02:00:00    527.835516\n",
       "2018-01-01 02:30:00    510.287339\n",
       "2018-01-01 03:00:00    484.318581\n",
       "2018-01-01 03:30:00    494.293924\n",
       "2018-01-01 04:00:00    495.898691\n",
       "2018-01-01 04:30:00    504.273963\n",
       "2018-01-01 05:00:00    491.837654\n",
       "2018-01-01 05:30:00    504.900328\n",
       "2018-01-01 06:00:00    518.542890\n",
       "2018-01-01 06:30:00    508.227377\n",
       "2018-01-01 07:00:00    492.701546\n",
       "2018-01-01 07:30:00    506.695879\n",
       "2018-01-01 08:00:00    515.964603\n",
       "2018-01-01 08:30:00    492.576360\n",
       "2018-01-01 09:00:00    498.114972\n",
       "2018-01-01 09:30:00    508.470433\n",
       "Freq: 30T, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=20, freq='30min'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    516.845407\n",
       "2018-01-01 02:00:00    527.835516\n",
       "2018-01-01 04:00:00    495.898691\n",
       "2018-01-01 06:00:00    518.542890\n",
       "2018-01-01 08:00:00    515.964603\n",
       "Freq: 2H, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    516.845407\n",
       "2018-01-01 02:25:00           NaN\n",
       "2018-01-01 04:50:00           NaN\n",
       "2018-01-01 07:15:00           NaN\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    516.845407\n",
       "2018-01-01 02:25:00    527.835516\n",
       "2018-01-01 04:50:00    504.273963\n",
       "2018-01-01 07:15:00    492.701546\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min', method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if you want to do some more \"advanced\" filling. For example, filling the new freq values with the \"mean\"? For that, we'll use resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Resampling a timeseries is converting it to another time frequency. If you're going from high frequency to low frequency, the process is called \"downsampling\", and it involves an aggregation process. For example, you have daily sales data, and you want to aggregate it by month. You'll be \"grouping\" your daily sales per month, and you need to decide the aggregation operation to perform. For example, `sum` to get the total sales per month, or `mean` to get the average sale. Let's use an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-30    482.965663\n",
       "2018-02-05    503.921899\n",
       "2018-02-12    508.788190\n",
       "2018-02-21    491.974206\n",
       "2018-03-09    519.917458\n",
       "2018-03-23    510.913895\n",
       "2018-03-28    506.757993\n",
       "2018-04-12    513.377969\n",
       "2018-04-21    478.386838\n",
       "2018-05-13    495.527795\n",
       "2018-05-29    506.797391\n",
       "2018-06-11    523.577395\n",
       "2018-07-15    511.704263\n",
       "2018-07-24    502.095249\n",
       "2018-09-07    501.543196\n",
       "2018-10-14    494.422986\n",
       "2018-11-26    491.299111\n",
       "2018-12-02    511.221760\n",
       "2018-12-18    496.276670\n",
       "2018-12-20    504.393265\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_days_2018 = pd.date_range(start='2018-01-01', end='2018-12-31', freq='D')\n",
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=np.random.choice(all_days_2018, size=20))\n",
    "\n",
    "ts.sort_index(inplace=True)\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "January sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-30    482.965663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482.9656633119952"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "February sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-02-05    503.921899\n",
       "2018-02-12    508.788190\n",
       "2018-02-21    491.974206\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504.684294312036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling**: We'll now use `resample` to \"group\" the sales monthly (downsampling our TimeSeries), and calculate the total sales per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-31     482.965663\n",
       "2018-02-28    1504.684294\n",
       "2018-03-31    1537.589347\n",
       "2018-04-30     991.764807\n",
       "2018-05-31    1002.325186\n",
       "2018-06-30     523.577395\n",
       "2018-07-31    1013.799512\n",
       "2018-08-31       0.000000\n",
       "2018-09-30     501.543196\n",
       "2018-10-31     494.422986\n",
       "2018-11-30     491.299111\n",
       "2018-12-31    1511.891695\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `M` means \"month end frequency. We could instead choose \"Month Start\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01     482.965663\n",
       "2018-02-01    1504.684294\n",
       "2018-03-01    1537.589347\n",
       "2018-04-01     991.764807\n",
       "2018-05-01    1002.325186\n",
       "2018-06-01     523.577395\n",
       "2018-07-01    1013.799512\n",
       "2018-08-01       0.000000\n",
       "2018-09-01     501.543196\n",
       "2018-10-01     494.422986\n",
       "2018-11-01     491.299111\n",
       "2018-12-01    1511.891695\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('MS').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which would of course yield the same results, but the index contains the first day of each month. More correctly speaking, in this example, we're collecting sales of _\"the period January 2018\"_. Pandas also has a `Period` type, which we can use with the `kind` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01     482.965663\n",
       "2018-02    1504.684294\n",
       "2018-03    1537.589347\n",
       "2018-04     991.764807\n",
       "2018-05    1002.325186\n",
       "2018-06     523.577395\n",
       "2018-07    1013.799512\n",
       "2018-08       0.000000\n",
       "2018-09     501.543196\n",
       "2018-10     494.422986\n",
       "2018-11     491.299111\n",
       "2018-12    1511.891695\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales = ts.resample('M', kind='period').sum()\n",
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
       "             '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12'],\n",
       "            dtype='period[M]', freq='M')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Index is a `PeriodIndex`. Each entry in the index is of type `pd.Period`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01', 'M')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period support basic arithmetic operations which makes them convenient to express these time ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-06', 'M')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01') + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01-01 09:00', 'H')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01', freq='H') + 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsampling**: With upsampling we'll convert a low-frequency time series to a higher frequency time series. We'll add more \"time points\". Let's use an example:\n",
    "\n",
    "We'll start with 3 months of sales, only 3 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    483.294815\n",
       "2018-02-01    498.828492\n",
       "2018-03-01    525.966153\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(3) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=3, freq='MS'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now `resample` it to be \"Semi Month\", every 15 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    483.294815\n",
       "2018-01-15           NaN\n",
       "2018-02-01    498.828492\n",
       "2018-02-15           NaN\n",
       "2018-03-01    525.966153\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see, we have a few missing values, because we don't have data for those specific time periods. What can you do with that missing data? One option is to fill it with previous data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    483.294815\n",
       "2018-01-15    483.294815\n",
       "2018-02-01    498.828492\n",
       "2018-02-15    498.828492\n",
       "2018-03-01    525.966153\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').ffill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
